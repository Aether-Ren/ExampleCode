{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from linear_operator import settings\n",
    "\n",
    "import pyro\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import arviz as az\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = pd.read_csv('Data/train3D.csv', delimiter=',')\n",
    "TestData = pd.read_csv('Data/test3D.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "TrainData_standardized = pd.DataFrame(scaler.fit_transform(TrainData), columns=TrainData.columns).values\n",
    "\n",
    "TestData_standardized = pd.DataFrame(scaler.fit_transform(TestData), columns=TestData.columns).values\n",
    "\n",
    "X_train = TrainData_standardized[:,0:2]\n",
    "Y_train = TrainData_standardized[:,-1]\n",
    "\n",
    "X_test = TestData_standardized[:,0:2]\n",
    "Y_test = TestData_standardized[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData_log = np.log(TrainData).values\n",
    "TestData_log = np.log(TestData).values\n",
    "\n",
    "X_train = TrainData_log[:,0]\n",
    "Y_train = TrainData_log[:,-1]\n",
    "\n",
    "X_test = TestData_log[:,0]\n",
    "Y_test = TestData_log[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32).to(Device)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32).to(Device)\n",
    "\n",
    "train_y = torch.tensor(Y_train, dtype=torch.float32).to(Device)\n",
    "test_y = torch.tensor(Y_test, dtype=torch.float32).to(Device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocalGP_models, LocalGP_likelihoods = Training.train_one_column_StandardGP(\n",
    "    train_x, train_y, covar_type='RBF', lr=0.05, num_iterations=5000, patience=10, device=Device, use_amp=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Prediction.preds_for_one_model(LocalGP_models, LocalGP_likelihoods, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Prediction.preds_for_one_model(LocalGP_models, LocalGP_likelihoods, test_x).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((preds - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "bounds = bound.get_bounds(train_x)\n",
    "\n",
    "estimated_params, func_loss = Estimation.multi_start_estimation(LocalGP_models, LocalGP_likelihoods, row_idx, test_y, bounds, Estimation.estimate_params_for_one_model_Adam, \n",
    "                                                                num_starts=5, num_iterations=2000, lr=0.01, patience=10, \n",
    "                                                                attraction_threshold=0.1, repulsion_strength=0.5, device=Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x[row_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only can run in .py\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    row_idx = 0\n",
    "\n",
    "    bounds = bound.get_bounds(train_x)\n",
    "\n",
    "    mcmc_result = Estimation.run_mcmc(LocalGP_models, LocalGP_likelihoods, row_idx, test_y, bounds, \n",
    "                                                  num_sampling = 1000, warmup_step = 200, num_chains=1, device=Device,jit_compile=False)\n",
    "    samples = mcmc_result.get_samples()\n",
    "    print(\"theta 后验样本：\", samples.get('theta'))\n",
    "    print(\"sigma 后验样本：\", samples.get('sigma'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples_Normal = mcmc_result.get_samples()\n",
    "\n",
    "\n",
    "true_values = test_x[row_idx, :].cpu().detach().numpy() if hasattr(test_x, \"cpu\") else test_x[row_idx, :]\n",
    "point_estimations = None\n",
    "\n",
    "num_params = len(posterior_samples_Normal)\n",
    "fig, axes = plt.subplots(num_params, 1, figsize=(8, num_params * 3))\n",
    "if num_params == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (param_name, samples) in enumerate(posterior_samples_Normal.items()):\n",
    "    ax = axes[i]\n",
    "    samples_np = samples.cpu().detach().numpy() if samples.device.type != 'cpu' else samples.detach().numpy()\n",
    "    sns.kdeplot(samples_np, ax=ax, color='blue')\n",
    "    ax.set_title(f'Density of {param_name}')\n",
    "    \n",
    "    if true_values is not None and i < len(true_values):\n",
    "        ax.axvline(true_values[i], color='red', linestyle='--', label='True Value')\n",
    "    if point_estimations is not None and i < len(point_estimations):\n",
    "        ax.axvline(point_estimations[i], color='green', linestyle='-.', label='Point Estimation')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FGPyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
